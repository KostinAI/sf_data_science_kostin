{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"t_IvORKWGuCH"},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"markdown","metadata":{"id":"FtTudvkQGzRk"},"source":["# Загрузка данных"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gmll87tAG2rK"},"outputs":[],"source":["data = pd.read_excel('/home/aleksandr/Документы/GitHub/data/ML6/data_ford_price.xlsx')"]},{"cell_type":"markdown","metadata":{"id":"zKZZVz_6IA1m"},"source":["#  Отбор признаков: мотивация"]},{"cell_type":"markdown","metadata":{},"source":["Отбор признаков — это процесс выбора важных признаков, оказывающих наибольшее влияние на предсказание."]},{"cell_type":"markdown","metadata":{"id":"dt3vhRQ2G_uP"},"source":["## Предобработка данных"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CJdK-t3MHDSp"},"outputs":[],"source":["# Давайте оценим влияние мультиколлинеарности на линейную регрессию:\n","data = data[['price','year', 'cylinders', 'odometer', 'lat', 'long', 'weather']]\n","data.dropna(inplace = True)\n","\n","y = data['price']\n","x = data.drop(columns='price')\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"markdown","metadata":{"id":"kqjEj0ABG4ZD"},"source":["## Обучение модели"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650361775695,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"K0aIWfwpHSHN","outputId":"9d5779ab-7fea-43e4-f7d6-62317dfcc079"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4682.957\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"TznnlORnHisT"},"source":["## Удаление избыточного признака"]},{"cell_type":"markdown","metadata":{},"source":["Мы выяснили, что у нас присутствует сильная зависимость между lat и weather. Удалим lat, так как этот признак, в отличие от weather, необходимо округлять."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2uKP_vEMHoBa"},"outputs":[],"source":["x.drop('lat', axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A7f7kV-6HrrL"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1650361779668,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"pJQpOM9kHtSe","outputId":"709029e0-e13b-4f2b-92f7-9fa807a81b0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4672.930\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"E54vkz2xIGWm"},"source":["#  Отбор признаков: классификация методов"]},{"cell_type":"markdown","metadata":{},"source":["Методы отбора признаков предназначены для уменьшения количества входных переменных до тех значений, которые наиболее полезны для предсказательной способности модели."]},{"cell_type":"markdown","metadata":{"id":"dUnTavGgIpj0"},"source":["## Метод рекурсивного исключения признаков\n","\n","Метод рекурсивного исключения признаков (RFE) предполагает выбор признаков путём рекурсивного рассмотрения всё меньших и меньших наборов фичей."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UYdiW0RWIZ5V"},"outputs":[],"source":["from sklearn.feature_selection import RFE"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"n3MW_xlPIJHd"},"outputs":[],"source":["y = data['price']\n","x = data.drop(columns='price')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uU5SYUHvOlbt"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650361787999,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"qxZGlxQYITTm","outputId":"cf3cfc7c-1bb2-4a2b-b8c4-26a5857e251a"},"outputs":[{"data":{"text/plain":["array(['year', 'cylinders', 'lat'], dtype=object)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Выделим три наиболее значимых признака:\n","estimator = LinearRegression()\n","selector = RFE(estimator, n_features_to_select=3, step=1)\n","selector = selector.fit(X_train, y_train)\n"," \n","selector.get_feature_names_out()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1650361789809,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"VdZbOvqdIebk","outputId":"ac89f779-2388-4185-8647-b8addd1cbfac"},"outputs":[{"data":{"text/plain":["Index(['year', 'cylinders', 'odometer', 'lat', 'long', 'weather'], dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# узнаем, как RFE проранжировал все доступные признаки:\n","X_train.columns"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1650361793169,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"QJ93ms5kIlS7","outputId":"ae52c597-f97e-4d2f-d679-fb7b9e29ed8a"},"outputs":[{"data":{"text/plain":["array([1, 1, 4, 1, 3, 2])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["selector.ranking_"]},{"cell_type":"markdown","metadata":{"id":"_KhZgXCkK3Ap"},"source":["##  МЕТОДЫ ВЫБОРА ПРИЗНАКОВ НА ОСНОВЕ ФИЛЬТРОВ"]},{"cell_type":"markdown","metadata":{},"source":["<center> <img src = https://lms.skillfactory.ru/assets/courseware/v1/8f55a77ec813c98e6e48f2efff923f23/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml6-9_3.png alt=\"drawing\" style=\"width:800px;\">"]},{"cell_type":"markdown","metadata":{},"source":["Библиотека sklearn обеспечивает реализацию большинства полезных статистических показателей, например:\n","- коэффициента корреляции Пирсона: f_regression();\n","- дисперсионного анализа ANOVA: f_classif();\n","- хи-квадрата: chi2();\n","- взаимной информации: mutual_info_classif() и mutual_info_regression().\n","\n","библиотека SciPy обеспечивает реализацию многих других статистических данных, таких как тау Кендалла (kendalltau) и ранговая корреляция Спирмена (spearmanr).\n","\n","sklearn также предоставляет множество различных методов фильтрации после расчёта статистики для каждой входной переменной с целевой.\n","- выбор k лучших переменных: SelectKBest;\n","- выбор переменных верхнего процентиля: SelectPercentile."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"mVHuMD0eK8or"},"outputs":[],"source":["from sklearn.feature_selection import SelectKBest, f_regression"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1650361806172,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"dc2EPKG5K39w","outputId":"4bc13ef2-9c06-47c6-f892-566135ee3dcd"},"outputs":[{"data":{"text/plain":["array(['year', 'cylinders', 'odometer'], dtype=object)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["selector = SelectKBest(f_regression, k=3)\n","selector.fit(X_train, y_train)\n"," \n","selector.get_feature_names_out()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Обучите модель линейной регрессии на найденных двумя способами трёх важных признаках и сравните полученные результаты.\n","# 1 балл\tВерно выделены три столбца-признака для обучения, выбранные RFE.\n","# 1 балл\tВерно выделены три столбца-признака для обучения, выбранные SelectKBest.\n","# 3 балла\tОбучена регрессия на первых трёх столбцах, оценено качество модели на тесте.\n","# 3 балла\tОбучена регрессия на вторых трёх столбцах, оценено качество модели на тесте.\n","# 2 балла\tПроизведено сравнение выбранных метрик в форме комментария (в текстовой ячейке)."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02oW-kA9K-ig"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Отбор_признаков.ipynb","provenance":[]},"interpreter":{"hash":"e7b67c4c70b37abe9a13cdef6d156c2045a2cb7d6c971e7027ad705fb56218cc"},"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
